{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Government Documents RAG System with LangGraph\n",
    "\n",
    "This notebook demonstrates how to build a RAG (Retrieval-Augmented Generation) system for government documents using LangGraph and Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import fitz  # PyMuPDF\n",
    "from typing import Annotated, List, Dict, Any, TypedDict, Optional\n",
    "from typing_extensions import TypedDict\n",
    "import sys\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma as LCChroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.schema import Document\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Processing\n",
    "\n",
    "We'll create a class to handle loading and processing documents from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from typing import List, Optional, Dict, Any\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, docs_dir: str, chunk_size: int = 1000, chunk_overlap: int = 200):\n",
    "        self.docs_dir = docs_dir\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap,\n",
    "            length_function=len,\n",
    "        )\n",
    "        \n",
    "    def extract_text_with_layout(self, pdf_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF while preserving layout information.\n",
    "        Uses PyMuPDF (fitz) to get better results with complex layouts.\n",
    "        \"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        extracted_data = []\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            \n",
    "            # Get page dimensions to determine orientation\n",
    "            width, height = page.rect.width, page.rect.height\n",
    "            orientation = \"landscape\" if width > height else \"portrait\"\n",
    "            \n",
    "            # Extract text blocks with their bounding boxes\n",
    "            blocks = page.get_text(\"blocks\")\n",
    "            \n",
    "            # Sort blocks - for dual column papers, sort by x coordinate first then y\n",
    "            if self._is_likely_multi_column(blocks):\n",
    "                # Use x coordinate to identify columns, then sort by y within columns\n",
    "                col_threshold = width / 2  # Simple assumption of a two-column layout\n",
    "                left_col = [b for b in blocks if b[0] < col_threshold]\n",
    "                right_col = [b for b in blocks if b[0] >= col_threshold]\n",
    "                \n",
    "                # Sort each column by y-coordinate\n",
    "                left_col.sort(key=lambda b: b[1])\n",
    "                right_col.sort(key=lambda b: b[1])\n",
    "                \n",
    "                # Process left column, then right column\n",
    "                sorted_blocks = left_col + right_col\n",
    "            else:\n",
    "                # Sort blocks by y-coordinate for standard top-to-bottom reading\n",
    "                sorted_blocks = sorted(blocks, key=lambda b: b[1])\n",
    "            \n",
    "            for block in sorted_blocks:\n",
    "                # Each block is (x0, y0, x1, y1, text, block_type, block_no)\n",
    "                block_text = block[4]\n",
    "                if block_text.strip():  # Skip empty blocks\n",
    "                    extracted_data.append({\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"text\": block_text,\n",
    "                        \"orientation\": orientation,\n",
    "                        \"bbox\": block[:4],  # Bounding box coordinates\n",
    "                    })\n",
    "        \n",
    "        return extracted_data\n",
    "    \n",
    "    def _is_likely_multi_column(self, blocks, threshold=0.3):\n",
    "        \"\"\"\n",
    "        Detect if a page likely has a multi-column layout.\n",
    "        \"\"\"\n",
    "        if not blocks:\n",
    "            return False\n",
    "            \n",
    "        # Extract x-coordinates where blocks start\n",
    "        x_starts = [b[0] for b in blocks]\n",
    "        \n",
    "        # Get page width from the maximum x-coordinate of any block\n",
    "        page_width = max(b[2] for b in blocks)\n",
    "        \n",
    "        # Count blocks that start in left vs right half of page\n",
    "        left_half = sum(1 for x in x_starts if x < page_width/2)\n",
    "        right_half = sum(1 for x in x_starts if x >= page_width/2)\n",
    "        \n",
    "        # If there's a significant number of blocks in both halves, likely multi-column\n",
    "        total_blocks = len(blocks)\n",
    "        return (left_half / total_blocks > threshold and \n",
    "                right_half / total_blocks > threshold)\n",
    "    \n",
    "    def load_documents(self) -> List[Document]:\n",
    "        \"\"\"Load documents from the specified directory with enhanced PDF processing\"\"\"\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(self.docs_dir):\n",
    "            os.makedirs(self.docs_dir)\n",
    "            print(f\"Created directory: {self.docs_dir}\")\n",
    "            return []\n",
    "        \n",
    "        # Process all PDF files with enhanced layout handling\n",
    "        pdf_docs = []\n",
    "        pdf_files = [f for f in os.listdir(self.docs_dir) \n",
    "                     if f.lower().endswith('.pdf')]\n",
    "        \n",
    "        for filename in pdf_files:\n",
    "            filepath = os.path.join(self.docs_dir, filename)\n",
    "            try:\n",
    "                print(f\"Processing PDF: {filename}\")\n",
    "                extracted_data = self.extract_text_with_layout(filepath)\n",
    "                \n",
    "                # Group content by page\n",
    "                pages = {}\n",
    "                for item in extracted_data:\n",
    "                    page_num = item[\"page\"]\n",
    "                    if page_num not in pages:\n",
    "                        pages[page_num] = []\n",
    "                    pages[page_num].append(item)\n",
    "                \n",
    "                # Create a document for each page\n",
    "                for page_num, page_items in pages.items():\n",
    "                    page_text = \"\\n\".join([item[\"text\"] for item in page_items])\n",
    "                    \n",
    "                    # Clean up text - replace excessive newlines and spaces\n",
    "                    page_text = re.sub(r'\\n{3,}', '\\n\\n', page_text)\n",
    "                    page_text = re.sub(r' {2,}', ' ', page_text)\n",
    "                    \n",
    "                    # Create document with metadata\n",
    "                    doc = Document(\n",
    "                        page_content=page_text,\n",
    "                        metadata={\n",
    "                            \"source\": filepath,\n",
    "                            \"page\": page_num,\n",
    "                            \"file_name\": filename,\n",
    "                        }\n",
    "                    )\n",
    "                    pdf_docs.append(doc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "        \n",
    "        # Load text files with standard TextLoader\n",
    "        text_docs = []\n",
    "        text_files = [f for f in os.listdir(self.docs_dir) \n",
    "                     if f.lower().endswith('.txt')]\n",
    "        \n",
    "        if text_files:\n",
    "            text_loader = DirectoryLoader(self.docs_dir, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "            text_docs = text_loader.load()\n",
    "        \n",
    "        # Combine all documents\n",
    "        all_docs = pdf_docs + text_docs\n",
    "        \n",
    "        print(f\"Loaded {len(all_docs)} documents\")\n",
    "        return all_docs\n",
    "    \n",
    "    def process_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"Split documents into chunks for vectorization\"\"\"\n",
    "        if not documents:\n",
    "            print(\"No documents to process\")\n",
    "            return []\n",
    "            \n",
    "        chunked_documents = self.text_splitter.split_documents(documents)\n",
    "        print(f\"Split into {len(chunked_documents)} chunks\")\n",
    "        return chunked_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector Store Setup\n",
    "\n",
    "Now let's create a vector store for document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, persist_directory: str = \"./chroma_db\"):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "        )\n",
    "        self.vectordb = None\n",
    "        \n",
    "    def create_or_load_db(self, documents: Optional[List[Document]] = None) -> Chroma:\n",
    "        \"\"\"Create a new vector store or load existing one\"\"\"\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(self.persist_directory):\n",
    "            os.makedirs(self.persist_directory)\n",
    "            \n",
    "        if documents and len(documents) > 0:\n",
    "            # Create a new vector store\n",
    "            print(f\"Creating new vector database with {len(documents)} documents\")\n",
    "            self.vectordb = LCChroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.persist_directory,\n",
    "            )\n",
    "            # The persist() call is no longer needed - removal fixes the error\n",
    "            # LCChroma automatically persists when persist_directory is provided\n",
    "            print(f\"Vector database created and persisted to {self.persist_directory}\")\n",
    "        else:\n",
    "            # Load existing vector store if it exists\n",
    "            try:\n",
    "                print(f\"Loading existing vector database from {self.persist_directory}\")\n",
    "                self.vectordb = LCChroma(\n",
    "                    persist_directory=self.persist_directory,\n",
    "                    embedding_function=self.embeddings,\n",
    "                )\n",
    "                print(f\"Successfully loaded vector database with {self.vectordb._collection.count()} documents\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading existing database: {e}\")\n",
    "                print(\"Creating an empty vector database instead\")\n",
    "                self.vectordb = LCChroma(\n",
    "                    embedding_function=self.embeddings,\n",
    "                    persist_directory=self.persist_directory,\n",
    "                )\n",
    "        \n",
    "        return self.vectordb\n",
    "    \n",
    "    def get_retriever(self, k: int = 4):\n",
    "        \"\"\"Get a retriever from the vector store\"\"\"\n",
    "        if self.vectordb is None:\n",
    "            raise ValueError(\"VectorDB not initialized. Call create_or_load_db first.\")\n",
    "        \n",
    "        return self.vectordb.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": k}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    retrieved_documents: Optional[List[Document]]\n",
    "\n",
    "class GovernmentDocsRAG:\n",
    "    def __init__(self, model_name: str = \"claude-3-5-sonnet-20240620\"):\n",
    "        self.memory = MemorySaver()\n",
    "        self.llm = ChatAnthropic(model=model_name)\n",
    "        \n",
    "        # Define system prompt for the chatbot\n",
    "        self.system_prompt = \"\"\"You are a helpful assistant specialized in answering questions about government documents. \n",
    "When responding:\n",
    "1. Base your answers on the retrieved documents\n",
    "2. If the documents don't contain the answer, say you don't know\n",
    "3. Always cite your sources by referencing the document name and section\n",
    "4. Be concise but thorough in your responses\n",
    "5. Format your response in a readable way\n",
    "\n",
    "Current retrieved documents for this query: {documents}\n",
    "\"\"\"\n",
    "        \n",
    "        # Initialize the graph\n",
    "        self.graph_builder = StateGraph(State)\n",
    "        \n",
    "    def build_graph(self, retriever):\n",
    "        \"\"\"Build the LangGraph flow\"\"\"\n",
    "        # Define the retriever node\n",
    "        def retrieve_documents(state: State) -> Dict[str, Any]:\n",
    "            \"\"\"Retrieve relevant documents based on the user query\"\"\"\n",
    "            # Get the latest user message\n",
    "            user_message = state[\"messages\"][-1].content\n",
    "            \n",
    "            # Retrieve documents\n",
    "            retrieved_docs = retriever.get_relevant_documents(user_message)\n",
    "            \n",
    "            # Format documents for better readability\n",
    "            return {\"retrieved_documents\": retrieved_docs}\n",
    "        \n",
    "        # Define the RAG node\n",
    "        def generate_response(state: State) -> Dict[str, Any]:\n",
    "            \"\"\"Generate a response using the LLM with retrieved documents\"\"\"\n",
    "            # Get documents\n",
    "            docs = state.get(\"retrieved_documents\", [])\n",
    "            \n",
    "            # Format documents for the prompt\n",
    "            doc_strings = []\n",
    "            for i, doc in enumerate(docs):\n",
    "                doc_strings.append(f\"Document {i+1}:\\nContent: {doc.page_content}\\nSource: {doc.metadata.get('source', 'Unknown')}\")\n",
    "            \n",
    "            formatted_docs = \"\\n\\n\".join(doc_strings)\n",
    "            \n",
    "            # Create prompt with documents\n",
    "            messages = state[\"messages\"].copy()\n",
    "            \n",
    "            # Add system prompt with documents\n",
    "            system_prompt_with_docs = self.system_prompt.format(documents=formatted_docs)\n",
    "            \n",
    "            # Create augmented LLM\n",
    "            llm_with_docs = self.llm.bind(system=system_prompt_with_docs)\n",
    "            \n",
    "            # Generate response\n",
    "            return {\"messages\": [llm_with_docs.invoke(messages)]}\n",
    "        \n",
    "        # Add nodes to the graph\n",
    "        self.graph_builder.add_node(\"retrieve\", retrieve_documents)\n",
    "        self.graph_builder.add_node(\"rag_response\", generate_response)\n",
    "        \n",
    "        # Add edges\n",
    "        self.graph_builder.add_edge(START, \"retrieve\")\n",
    "        self.graph_builder.add_edge(\"retrieve\", \"rag_response\")\n",
    "        self.graph_builder.add_edge(\"rag_response\", END)\n",
    "        \n",
    "        # Compile the graph\n",
    "        self.graph = self.graph_builder.compile(checkpointer=self.memory)\n",
    "        \n",
    "        return self.graph\n",
    "    \n",
    "    def chat(self, user_input: str, thread_id: str = \"default\"):\n",
    "        \"\"\"Chat with the RAG system\"\"\"\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        result = self.graph.invoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "            config,\n",
    "        )\n",
    "        \n",
    "        # Return the AI's response\n",
    "        return result[\"messages\"][-1].content\n",
    "    \n",
    "    def get_conversation_history(self, thread_id: str = \"default\"):\n",
    "        \"\"\"Get the full conversation history\"\"\"\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        state = self.graph.get_state(config)\n",
    "        \n",
    "        # Return all messages if available\n",
    "        if state and \"messages\" in state.values:\n",
    "            return state.values[\"messages\"]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set Up the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: H.R.1968 - Full-Year Continuing Appropriations and Extensions Act, 03-14-2025.pdf\n",
      "Loaded 102 documents\n",
      "Split into 201 chunks\n"
     ]
    }
   ],
   "source": [
    "# Process the sample documents\n",
    "doc_processor = DocumentProcessor(docs_dir=\"./documents\")\n",
    "raw_docs = doc_processor.load_documents()\n",
    "processed_docs = doc_processor.process_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3519/1818294722.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497175a8f81f42fc9afa25b4a221c506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bead102627be4517ad2bc1b36dde3ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46578dde11c4fac8e75bf228d0f870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323d79ba9d7f4373bc78e9db3b9151bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fcef68f72e47ee8868cb3a9243f5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7126e7847842ad9ec041d2c7e573bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8a73203e60472aad0e7b777425a134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ebaea1ff094df48bb4d70dd71ebe75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3660aa3cdaf54c759e8c47e59dc46a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe1216f964a4cd59204cb231c38230c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae28a32d8dc4bda99ab9e1aecc072a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector database with 201 documents\n",
      "Vector database created and persisted to ./docs_db\n"
     ]
    }
   ],
   "source": [
    "# Set up the vector store\n",
    "vector_store = VectorStore(persist_directory=\"./docs_db\")\n",
    "vector_db = vector_store.create_or_load_db(documents=processed_docs)\n",
    "retriever = vector_store.get_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f0f8c341d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the RAG system\n",
    "rag_system = GovernmentDocsRAG()\n",
    "rag_system.build_graph(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Interactions\n",
    "\n",
    "Let's interact with our RAG system by asking questions about the government documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many titles are there in division B, and what is division B about?\n",
      "Response: Based on the information provided in the retrieved documents, I can answer part of your question:\n",
      "\n",
      "Division B of the bill is titled \"HEALTH\" and contains at least one title:\n",
      "\n",
      "TITLE Iâ€”PUBLIC HEALTH EXTENDERS\n",
      "\n",
      "This information comes from Document 3, which shows the table of contents for the bill.\n",
      "\n",
      "However, I cannot definitively state how many total titles are in Division B, as the documents provided do not show a complete list of titles for this division. The information given only shows Title I, but there may be additional titles that are not visible in the excerpts provided.\n",
      "\n",
      "To summarize, Division B is about Health, and it contains at least one title focused on Public Health Extenders. For a complete count of titles in Division B, we would need to consult the full text of the bill.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Ask about education policy\n",
    "question1 = \"How many titles are there in division B, and what is division B about?\"\n",
    "print(f\"Question: {question1}\")\n",
    "response1 = rag_system.chat(question1, thread_id=\"demo_session\")\n",
    "print(f\"Response: {response1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How does HR1968 affect funding for low-income programs?\n",
      "Response: Based on the limited information provided in the retrieved documents, I cannot give a comprehensive answer about how HR 1968 affects funding for all low-income programs. The documents do not contain specific details about funding changes for most low-income programs.\n",
      "\n",
      "However, I can provide one relevant piece of information from the documents:\n",
      "\n",
      "The bill appears to extend and increase funding for certain programs that assist low-income individuals, particularly in accessing healthcare information and resources. Specifically:\n",
      "\n",
      "1. State Health Insurance Assistance Programs: Funding is increased from $22,500,000 to $30,000,000 and extended to September 30, 2025 (previously March 31, 2025).\n",
      "\n",
      "2. Area Agencies on Aging: Funding is increased from $22,500,000 to $30,000,000 and extended to September 30, 2025.\n",
      "\n",
      "3. Aging and Disability Resource Centers: Funding is increased from $8,500,000 to $10,000,000 and extended to September 30, 2025.\n",
      "\n",
      "This information comes from Document 3, Section 2205.\n",
      "\n",
      "Beyond these specific programs, I don't have enough information from the provided documents to comment on how HR 1968 affects other low-income programs. If you need more comprehensive information, you may need to consult the full text of the bill or additional sources.\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Ask about healthcare reform\n",
    "question2 = \"How does HR1968 affect funding for low-income programs?\"\n",
    "print(f\"Question: {question2}\")\n",
    "response2 = rag_system.chat(question2, thread_id=\"demo_session\")\n",
    "print(f\"Response: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Ask a follow-up question to test memory\n",
    "question3 = \"When will these funding mechanisms be implemented?\"\n",
    "print(f\"Question: {question3}\")\n",
    "response3 = rag_system.chat(question3, thread_id=\"demo_session\")\n",
    "print(f\"Response: {response3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Ask about environmental regulations\n",
    "question4 = \"What are the new carbon emission targets for power plants?\"\n",
    "print(f\"Question: {question4}\")\n",
    "response4 = rag_system.chat(question4, thread_id=\"demo_session\")\n",
    "print(f\"Response: {response4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Ask about something not in the documents\n",
    "question5 = \"What is the government's policy on international trade?\"\n",
    "print(f\"Question: {question5}\")\n",
    "response5 = rag_system.chat(question5, thread_id=\"demo_session\")\n",
    "print(f\"Response: {response5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get Conversation History\n",
    "\n",
    "Let's retrieve the full conversation history to verify that our memory is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HumanMessage' object has no attribute 'role'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m history = rag_system.get_conversation_history(thread_id=\u001b[33m\"\u001b[39m\u001b[33mdemo_session\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(history):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrole\u001b[49m == \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pydantic/main.py:984\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    983\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'HumanMessage' object has no attribute 'role'"
     ]
    }
   ],
   "source": [
    "# Get conversation history\n",
    "history = rag_system.get_conversation_history(thread_id=\"demo_session\")\n",
    "for i, message in enumerate(history):\n",
    "    if message.role == \"user\":\n",
    "        print(f\"User: {message.content}\")\n",
    "    else:\n",
    "        print(f\"Assistant: {message.content[:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Working with Your Own Government Documents\n",
    "\n",
    "To use this system with your own government documents:\n",
    "\n",
    "1. Create a directory for your documents\n",
    "2. Add your PDF and/or text files to this directory\n",
    "3. Update the document processor to point to your directory\n",
    "4. Run the processing and vector store creation steps\n",
    "5. Initialize the RAG system with your retriever\n",
    "\n",
    "Here's a template for how you would do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Set up with your own documents\n",
    "'''\n",
    "# Define your documents directory\n",
    "my_docs_dir = \"./my_government_docs\"\n",
    "\n",
    "# Process your documents\n",
    "doc_processor = DocumentProcessor(docs_dir=my_docs_dir)\n",
    "raw_docs = doc_processor.load_documents()\n",
    "processed_docs = doc_processor.process_documents(raw_docs)\n",
    "\n",
    "# Set up vector store with your documents\n",
    "vector_store = VectorStore(persist_directory=\"./my_government_docs_db\")\n",
    "vector_db = vector_store.create_or_load_db(documents=processed_docs)\n",
    "retriever = vector_store.get_retriever(k=4)\n",
    "\n",
    "# Set up RAG system\n",
    "rag_system = GovernmentDocsRAG()\n",
    "rag_system.build_graph(retriever)\n",
    "\n",
    "# Start interacting\n",
    "response = rag_system.chat(\"What is the government's policy on X?\", thread_id=\"my_session\")\n",
    "print(response)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langgraph Python 3.11",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
